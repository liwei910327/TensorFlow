{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUtoed20cRJJ"
   },
   "source": [
    "# Load CSV data in TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-3Xbt0FfGfs"
   },
   "source": [
    "Introduction on how to use CSV data with TensorFlow.\n",
    "\n",
    "1. **Loading the data off disk**\n",
    "2. **Pre-processing it into a form suitable for training.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgZ9gjmPfSnK"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:05:59.655386Z",
     "iopub.status.busy": "2021-06-16T15:05:59.654802Z",
     "iopub.status.idle": "2021-06-16T15:06:01.305280Z",
     "shell.execute_reply": "2021-06-16T15:06:01.304759Z"
    },
    "id": "baYFZMW_bJHh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZhJYbJxHNGJ"
   },
   "source": [
    "## In memory data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ny5TEgcmHjVx"
   },
   "source": [
    "For any small CSV dataset the simplest way to train a TensorFlow model on it is to load it into memory as a pandas Dataframe or a NumPy array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgpBOuU8PGFf"
   },
   "source": [
    "A relatively simple example is the [abalone dataset]\n",
    "\n",
    "* The dataset is small. \n",
    "* All the input features are all limited-range floating point values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:01.311917Z",
     "iopub.status.busy": "2021-06-16T15:06:01.311290Z",
     "iopub.status.idle": "2021-06-16T15:06:01.536335Z",
     "shell.execute_reply": "2021-06-16T15:06:01.536703Z"
    },
    "id": "IZVExo9DKoNz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlfGrk_9N-wf"
   },
   "source": [
    "The nominal task for this dataset is to predict the age from the other measurements, so separate the features and labels for training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:01.541359Z",
     "iopub.status.busy": "2021-06-16T15:06:01.540764Z",
     "iopub.status.idle": "2021-06-16T15:06:01.542616Z",
     "shell.execute_reply": "2021-06-16T15:06:01.542947Z"
    },
    "id": "udOnDJOxNi7p"
   },
   "outputs": [],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seK9n71-UBfT"
   },
   "source": [
    "Treat all features identically. Pack the features into a single NumPy array.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:01.546707Z",
     "iopub.status.busy": "2021-06-16T15:06:01.545558Z",
     "iopub.status.idle": "2021-06-16T15:06:01.549328Z",
     "shell.execute_reply": "2021-06-16T15:06:01.549702Z"
    },
    "id": "Dp3N5McbUMwb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.435, 0.335, 0.11 , ..., 0.136, 0.077, 0.097],\n",
       "       [0.585, 0.45 , 0.125, ..., 0.354, 0.207, 0.225],\n",
       "       [0.655, 0.51 , 0.16 , ..., 0.396, 0.282, 0.37 ],\n",
       "       ...,\n",
       "       [0.53 , 0.42 , 0.13 , ..., 0.374, 0.167, 0.249],\n",
       "       [0.395, 0.315, 0.105, ..., 0.118, 0.091, 0.119],\n",
       "       [0.45 , 0.355, 0.12 , ..., 0.115, 0.067, 0.16 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_features = np.array(abalone_features)\n",
    "abalone_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C1yFOxLOdxh"
   },
   "source": [
    "Make a regression model predict the age. Since there is only a single input tensor, a `keras.Sequential` model is sufficient here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:01.553697Z",
     "iopub.status.busy": "2021-06-16T15:06:01.553111Z",
     "iopub.status.idle": "2021-06-16T15:06:03.124002Z",
     "shell.execute_reply": "2021-06-16T15:06:03.124378Z"
    },
    "id": "d8zzNrZqOmfB"
   },
   "outputs": [],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6IWeP78O2wE"
   },
   "source": [
    "To train that model, pass the features and labels to `Model.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:03.128813Z",
     "iopub.status.busy": "2021-06-16T15:06:03.128266Z",
     "iopub.status.idle": "2021-06-16T15:06:05.328650Z",
     "shell.execute_reply": "2021-06-16T15:06:05.328996Z"
    },
    "id": "uZdpCD92SN3Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 10s 2ms/step - loss: 62.8223\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 11.7930\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 4s 41ms/step - loss: 8.4208\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 7.9564A: 0s - loss: 7.89\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 7.5468\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 7.1996\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.9527\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.7499\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 4s 37ms/step - loss: 6.6172\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.5077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15888e1a640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GapLOj1OOTQH"
   },
   "source": [
    "Next is about how to apply preprocessing to normalize numeric columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B87Rd1SOUv02"
   },
   "source": [
    "## Basic preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCrB2Jd-U0Vt"
   },
   "source": [
    "It's good practice to normalize the inputs before fed to model. The `experimental.preprocessing` layers provide a convenient way to build this normalization into the model. The layer will precompute the mean and variance of each column, and use these to normalize the data.\n",
    "\n",
    "First step is to create the layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:05.334664Z",
     "iopub.status.busy": "2021-06-16T15:06:05.333879Z",
     "iopub.status.idle": "2021-06-16T15:06:05.336321Z",
     "shell.execute_reply": "2021-06-16T15:06:05.335913Z"
    },
    "id": "H2WQpDU5VRk7"
   },
   "outputs": [],
   "source": [
    "normalize = preprocessing.Normalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGgEZE-7Vpt6"
   },
   "source": [
    "Then use the `Normalization.adapt()` method to adapt the normalization layer to the data.\n",
    "\n",
    "Note: Only use training data to `.adapt()` preprocessing layers. Do not use validation or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:05.340550Z",
     "iopub.status.busy": "2021-06-16T15:06:05.339687Z",
     "iopub.status.idle": "2021-06-16T15:06:05.565468Z",
     "shell.execute_reply": "2021-06-16T15:06:05.565895Z"
    },
    "id": "2WgOPIiOVpLg"
   },
   "outputs": [],
   "source": [
    "normalize.adapt(abalone_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE6vh0byV7cE"
   },
   "source": [
    "Then use the normalization layer in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:05.572519Z",
     "iopub.status.busy": "2021-06-16T15:06:05.571951Z",
     "iopub.status.idle": "2021-06-16T15:06:07.440968Z",
     "shell.execute_reply": "2021-06-16T15:06:07.441352Z"
    },
    "id": "quPcZ9dTWA9A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 94.2030\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 56.1165\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 17.8982\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.0464\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 4s 39ms/step - loss: 5.1243\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.0472\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.0215\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.0311\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.9768\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.9536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x158f8c2e5e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_abalone_model = tf.keras.Sequential([\n",
    "  normalize,\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.optimizers.Adam())\n",
    "\n",
    "norm_abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wuqj601Qw0Ml"
   },
   "source": [
    "## Mixed data types\n",
    "\n",
    "The \"Titanic\" dataset contains information about the passengers on the Titanic. The nominal task on this dataset is to predict who survived. \n",
    "\n",
    "The raw data can easily be loaded as a Pandas `DataFrame`, but is not immediately usable as input to a TensorFlow model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.445405Z",
     "iopub.status.busy": "2021-06-16T15:06:07.444810Z",
     "iopub.status.idle": "2021-06-16T15:06:07.643981Z",
     "shell.execute_reply": "2021-06-16T15:06:07.643505Z"
    },
    "id": "GS-dBMpuYMnz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.648418Z",
     "iopub.status.busy": "2021-06-16T15:06:07.647871Z",
     "iopub.status.idle": "2021-06-16T15:06:07.649895Z",
     "shell.execute_reply": "2021-06-16T15:06:07.649474Z"
    },
    "id": "D8rCGIK1ZzKx"
   },
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urHOwpCDYtcI"
   },
   "source": [
    "Because of the different data types and ranges, it is impossible to simply stack the features into  NumPy array and pass it to a `keras.Sequential` model. Each column needs to be handled individually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bta4Sx0Zau5v"
   },
   "source": [
    "Build a model that implements the preprocessing logic using [Keras functional API] The functional API operates on \"symbolic\" tensors. Normal \"eager\" tensors have a value. In contrast these \"symbolic\" tensors do not. Instead they keep track of which operations are run on them, and build representation of the calculation, that can be run later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.656233Z",
     "iopub.status.busy": "2021-06-16T15:06:07.655659Z",
     "iopub.status.idle": "2021-06-16T15:06:07.662460Z",
     "shell.execute_reply": "2021-06-16T15:06:07.662792Z"
    },
    "id": "730F16_97D-3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None,) dtype=float32 (created by layer 'tf.__operators__.add')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Do a calculation using is\n",
    "result = 2*input + 1\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.666950Z",
     "iopub.status.busy": "2021-06-16T15:06:07.666418Z",
     "iopub.status.idle": "2021-06-16T15:06:07.669882Z",
     "shell.execute_reply": "2021-06-16T15:06:07.669444Z"
    },
    "id": "RtcNXWB18kMJ"
   },
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.673050Z",
     "iopub.status.busy": "2021-06-16T15:06:07.672115Z",
     "iopub.status.idle": "2021-06-16T15:06:07.678085Z",
     "shell.execute_reply": "2021-06-16T15:06:07.677647Z"
    },
    "id": "fUGQOUqZ8sa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(calc(1).numpy())\n",
    "print(calc(2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNS9lT7f6_U2"
   },
   "source": [
    "To build the preprocessing model, start by building a set of symbolic `keras.Input` objects, matching the names and data-types of the CSV columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.689311Z",
     "iopub.status.busy": "2021-06-16T15:06:07.688668Z",
     "iopub.status.idle": "2021-06-16T15:06:07.691430Z",
     "shell.execute_reply": "2021-06-16T15:06:07.690962Z"
    },
    "id": "5WODe_1da3yw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'sex')>,\n",
       " 'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'n_siblings_spouses': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'n_siblings_spouses')>,\n",
       " 'parch': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'parch')>,\n",
       " 'fare': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'fare')>,\n",
       " 'class': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'class')>,\n",
       " 'deck': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'deck')>,\n",
       " 'embark_town': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'embark_town')>,\n",
       " 'alone': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'alone')>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaheJFmymq8l"
   },
   "source": [
    "The first step in the preprocessing logic is to concatenate the numeric inputs together, and run them through a normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.696861Z",
     "iopub.status.busy": "2021-06-16T15:06:07.696254Z",
     "iopub.status.idle": "2021-06-16T15:06:07.844565Z",
     "shell.execute_reply": "2021-06-16T15:06:07.844044Z"
    },
    "id": "wPRC_E6rkp8D"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'normalization_1')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JoR45Uj712l"
   },
   "source": [
    "Collect all the symbolic preprocessing results, to concatenate them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.848480Z",
     "iopub.status.busy": "2021-06-16T15:06:07.847860Z",
     "iopub.status.idle": "2021-06-16T15:06:07.849825Z",
     "shell.execute_reply": "2021-06-16T15:06:07.850196Z"
    },
    "id": "M7jIJw5XntdN"
   },
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0Hryylyosfm"
   },
   "source": [
    "For the string inputs use the `preprocessing.StringLookup` function to map from strings to integer indices in a vocabulary. Next, use `preprocessing.CategoryEncoding` to convert the indexes into `float32` data appropriate for the model. \n",
    "\n",
    "The default settings for the `preprocessing.CategoryEncoding` layer create a one-hot vector for each input. A `layers.Embedding` would also work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.856094Z",
     "iopub.status.busy": "2021-06-16T15:06:07.855479Z",
     "iopub.status.idle": "2021-06-16T15:06:07.948237Z",
     "shell.execute_reply": "2021-06-16T15:06:07.948594Z"
    },
    "id": "79fi1Cgan2YV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n",
      "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n",
      "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n",
      "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n",
      "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n",
      "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n"
     ]
    }
   ],
   "source": [
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "  \n",
    "  lookup = preprocessing.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnhv0T7itnc7"
   },
   "source": [
    "With the collection of `inputs` and `processed_inputs`, concatenate all the preprocessed inputs together, and build a model that handles the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:07.953618Z",
     "iopub.status.busy": "2021-06-16T15:06:07.952938Z",
     "iopub.status.idle": "2021-06-16T15:06:08.174393Z",
     "shell.execute_reply": "2021-06-16T15:06:08.174786Z"
    },
    "id": "XJRzUTe8ukXc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNHxrNW8vdda"
   },
   "source": [
    "This `model` just contains the input preprocessing.  Keras models don't automatically convert Pandas `DataFrames` because it's not clear if it should be converted to one tensor or to a dictionary of tensors. So convert it to a dictionary of tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:08.179391Z",
     "iopub.status.busy": "2021-06-16T15:06:08.178853Z",
     "iopub.status.idle": "2021-06-16T15:06:08.180640Z",
     "shell.execute_reply": "2021-06-16T15:06:08.180981Z"
    },
    "id": "5YjdYyMEacwQ"
   },
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nKJYoPByada"
   },
   "source": [
    "Slice out the first training example and pass it to this preprocessing model, it can be seen that the numeric features and string one-hots all concatenated together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:08.186232Z",
     "iopub.status.busy": "2021-06-16T15:06:08.185678Z",
     "iopub.status.idle": "2021-06-16T15:06:08.206257Z",
     "shell.execute_reply": "2021-06-16T15:06:08.206610Z"
    },
    "id": "SjnmU8PSv8T3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 33), dtype=float32, numpy=\n",
       "array([[-0.61 ,  0.395, -0.479, -0.497,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkBf4LvmzMDp"
   },
   "source": [
    "Now build the model on top of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:08.213579Z",
     "iopub.status.busy": "2021-06-16T15:06:08.213010Z",
     "iopub.status.idle": "2021-06-16T15:06:08.312816Z",
     "shell.execute_reply": "2021-06-16T15:06:08.312307Z"
    },
    "id": "coIPtGaCzUV7"
   },
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam())\n",
    "  return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LK5uBQQF2KbZ"
   },
   "source": [
    "When train the model, pass the dictionary of features as `x`, and the label as `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:08.317499Z",
     "iopub.status.busy": "2021-06-16T15:06:08.316594Z",
     "iopub.status.idle": "2021-06-16T15:06:09.585636Z",
     "shell.execute_reply": "2021-06-16T15:06:09.586008Z"
    },
    "id": "D1gVfwJ61ejz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 5s 5ms/step - loss: 0.6984\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5689\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5069\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4747\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4557\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4424\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4347\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4289\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4278\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 4s 222ms/step - loss: 0.4252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x159c5b6b5e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxgJarZk3bfH"
   },
   "source": [
    "Save the model and reload it somewhere else and get identical results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:09.592631Z",
     "iopub.status.busy": "2021-06-16T15:06:09.592037Z",
     "iopub.status.idle": "2021-06-16T15:06:13.189243Z",
     "shell.execute_reply": "2021-06-16T15:06:13.189671Z"
    },
    "id": "Ay-8ymNA2ZCh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n"
     ]
    }
   ],
   "source": [
    "titanic_model.save('test')\n",
    "reloaded = tf.keras.models.load_model('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:13.196042Z",
     "iopub.status.busy": "2021-06-16T15:06:13.195325Z",
     "iopub.status.idle": "2021-06-16T15:06:13.226812Z",
     "shell.execute_reply": "2021-06-16T15:06:13.226324Z"
    },
    "id": "Qm6jMTpD20lK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.802]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-1.802]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VsPlxIRZpXf"
   },
   "source": [
    "## Using tf.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyVDCwGzR5HW"
   },
   "source": [
    "Use `tf.data` to get more control over the input data pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP5Y1jM2Sor0"
   },
   "source": [
    "### On in memory data\n",
    "\n",
    "As a first example of applying `tf.data` to CSV data consider the following code to manually slice up the dictionary of features from the previous section. For each index, it takes that index for each feature:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:13.231602Z",
     "iopub.status.busy": "2021-06-16T15:06:13.230941Z",
     "iopub.status.idle": "2021-06-16T15:06:13.232995Z",
     "shell.execute_reply": "2021-06-16T15:06:13.233331Z"
    },
    "id": "i8wE-MVuVu7_"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "  for i in itertools.count():\n",
    "    # For each feature take index `i`\n",
    "    example = {name:values[i] for name, values in features.items()}\n",
    "    yield example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ3RTbS9YEal"
   },
   "source": [
    "Run this and print the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:13.237508Z",
     "iopub.status.busy": "2021-06-16T15:06:13.236917Z",
     "iopub.status.idle": "2021-06-16T15:06:13.239422Z",
     "shell.execute_reply": "2021-06-16T15:06:13.238976Z"
    },
    "id": "Wwq8XK88WwFk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : male\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : Third\n",
      "deck               : unknown\n",
      "embark_town        : Southampton\n",
      "alone              : n\n"
     ]
    }
   ],
   "source": [
    "for example in slices(titanic_features_dict):\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvp8Dct6YOIE"
   },
   "source": [
    "The most basic `tf.data.Dataset` in memory data loader is the `Dataset.from_tensor_slices` constructor. This returns a `tf.data.Dataset` that implements a generalized version of the above `slices` function, in TensorFlow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:13.243801Z",
     "iopub.status.busy": "2021-06-16T15:06:13.243075Z",
     "iopub.status.idle": "2021-06-16T15:06:13.245721Z",
     "shell.execute_reply": "2021-06-16T15:06:13.245225Z"
    },
    "id": "2gEJthslYxeV"
   },
   "outputs": [],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZC0rTpMZMZK"
   },
   "source": [
    "Iterate over a `tf.data.Dataset` like any other python iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:13.250067Z",
     "iopub.status.busy": "2021-06-16T15:06:13.249264Z",
     "iopub.status.idle": "2021-06-16T15:06:13.258251Z",
     "shell.execute_reply": "2021-06-16T15:06:13.258680Z"
    },
    "id": "gOHbiefaY4ag"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : b'male'\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : b'Third'\n",
      "deck               : b'unknown'\n",
      "embark_town        : b'Southampton'\n",
      "alone              : b'n'\n"
     ]
    }
   ],
   "source": [
    "for example in features_ds:\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwcFoVJWZY5F"
   },
   "source": [
    "The `from_tensor_slices` function can handle any structure of nested dictionaries or tuples. The following code makes a dataset of `(features_dict, labels)` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:13.264485Z",
     "iopub.status.busy": "2021-06-16T15:06:13.263871Z",
     "iopub.status.idle": "2021-06-16T15:06:13.266174Z",
     "shell.execute_reply": "2021-06-16T15:06:13.266560Z"
    },
    "id": "xIHGBy76Zcrx"
   },
   "outputs": [],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQwxitt8c2GK"
   },
   "source": [
    "To train a model using this `Dataset`, at least `shuffle` and `batch` the data need to be conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:13.270299Z",
     "iopub.status.busy": "2021-06-16T15:06:13.269727Z",
     "iopub.status.idle": "2021-06-16T15:06:13.275863Z",
     "shell.execute_reply": "2021-06-16T15:06:13.275353Z"
    },
    "id": "SbJcbldhddeC"
   },
   "outputs": [],
   "source": [
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4FRqhRFuoJx"
   },
   "source": [
    "Instead of passing `features` and `labels` to `Model.fit`, it will pass the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:13.280218Z",
     "iopub.status.busy": "2021-06-16T15:06:13.279646Z",
     "iopub.status.idle": "2021-06-16T15:06:14.070534Z",
     "shell.execute_reply": "2021-06-16T15:06:14.070921Z"
    },
    "id": "8yXkNPumdBtB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4244\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4214\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4209\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4196\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x159e8614460>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXuibiv9exT7"
   },
   "source": [
    "### From a single file\n",
    "\n",
    "So far this tutorial has worked with in-memory data. `tf.data` is a highly scalable toolkit for building data pipelines, and provides a few functions for dealing loading CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:14.075139Z",
     "iopub.status.busy": "2021-06-16T15:06:14.074463Z",
     "iopub.status.idle": "2021-06-16T15:06:14.085468Z",
     "shell.execute_reply": "2021-06-16T15:06:14.084933Z"
    },
    "id": "Ncf5t6tgL5ZI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "32768/30874 [===============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4N-plO4tDXd"
   },
   "source": [
    "Now read the CSV data from the file and create a `tf.data.Dataset`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:14.089603Z",
     "iopub.status.busy": "2021-06-16T15:06:14.088960Z",
     "iopub.status.idle": "2021-06-16T15:06:14.129882Z",
     "shell.execute_reply": "2021-06-16T15:06:14.129370Z"
    },
    "id": "yIbUscB9sqha"
   },
   "outputs": [],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file_path,\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='survived',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf3v3BKgy4AG"
   },
   "source": [
    "This function includes many convenient features so the data is easy to work with. This includes:\n",
    "\n",
    "* Using the column headers as dictionary keys.\n",
    "* Automatically determining the type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:14.134391Z",
     "iopub.status.busy": "2021-06-16T15:06:14.133755Z",
     "iopub.status.idle": "2021-06-16T15:06:14.168343Z",
     "shell.execute_reply": "2021-06-16T15:06:14.167782Z"
    },
    "id": "v4oMO9MIxgTG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'female' b'male' b'male' b'male' b'male']\n",
      "age                 : [33. 28. 31. 32. 17.]\n",
      "n_siblings_spouses  : [1 0 1 0 0]\n",
      "parch               : [2 0 0 0 0]\n",
      "fare                : [27.75   7.725 57.     7.75   7.125]\n",
      "class               : [b'Second' b'Third' b'First' b'Third' b'Third']\n",
      "deck                : [b'unknown' b'unknown' b'B' b'unknown' b'unknown']\n",
      "embark_town         : [b'Southampton' b'Queenstown' b'Southampton' b'Queenstown' b'Southampton']\n",
      "alone               : [b'n' b'y' b'n' b'y' b'y']\n",
      "\n",
      "label               : [1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in titanic_csv_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-TgA6o2Ja6U"
   },
   "source": [
    "Note: if run the above cell twice it will produce different results. The default settings for `make_csv_dataset` include `shuffle_buffer_size=1000`, which is more than sufficient for this small dataset, but may not be for a real-world dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:14.172575Z",
     "iopub.status.busy": "2021-06-16T15:06:14.171932Z",
     "iopub.status.idle": "2021-06-16T15:06:15.491200Z",
     "shell.execute_reply": "2021-06-16T15:06:15.490749Z"
    },
    "id": "kT7oZI2E46Q8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\n",
      "409600/405373 [==============================] - 1s 2us/step\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz', \n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "    cache_dir='.', cache_subdir='traffic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-IOsFHbCw0i"
   },
   "source": [
    "Set the `compression_type` argument to read directly from the compressed file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:15.496340Z",
     "iopub.status.busy": "2021-06-16T15:06:15.495702Z",
     "iopub.status.idle": "2021-06-16T15:06:15.687688Z",
     "shell.execute_reply": "2021-06-16T15:06:15.687138Z"
    },
    "id": "ar0MPEVJ5NeA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday             : [b'None' b'None' b'None' b'None' b'None']\n",
      "temp                : [295.21 295.81 281.21 266.74 289.67]\n",
      "rain_1h             : [0. 0. 0. 0. 0.]\n",
      "snow_1h             : [0. 0. 0. 0. 0.]\n",
      "clouds_all          : [90 92 20 90 90]\n",
      "weather_main        : [b'Clouds' b'Rain' b'Clouds' b'Snow' b'Rain']\n",
      "weather_description : [b'overcast clouds' b'light rain' b'few clouds' b'heavy snow'\n",
      " b'light rain']\n",
      "date_time           : [b'2013-06-24 10:00:00' b'2013-07-26 21:00:00' b'2012-10-16 00:00:00'\n",
      " b'2013-02-24 02:00:00' b'2013-05-09 20:00:00']\n",
      "\n",
      "label               : [4764 2917  500  612 3319]\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n",
    "    traffic_volume_csv_gz,\n",
    "    batch_size=256,\n",
    "    label_name='traffic_volume',\n",
    "    num_epochs=1,\n",
    "    compression_type=\"GZIP\")\n",
    "\n",
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value[:5]}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtrAXzYGP3l0"
   },
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN2dL_LRP83r"
   },
   "source": [
    "There is some overhead to parsing the csv data. For small models this can be the bottleneck in training. Depending on the use case it may be a good idea to use `Dataset.cache` or `data.experimental.snapshot` so that the csv data is only parsed on the first epoch. \n",
    "\n",
    "The main difference between the `cache` and `snapshot` methods is that `cache` files can only be used by the TensorFlow process that created them, but `snapshot` files can be read by other processes. For example, iterating over the `traffic_volume_csv_gz_ds` 20 times, takes ~15 seconds without caching, or ~2s with caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:15.692368Z",
     "iopub.status.busy": "2021-06-16T15:06:15.691810Z",
     "iopub.status.idle": "2021-06-16T15:06:26.678566Z",
     "shell.execute_reply": "2021-06-16T15:06:26.678119Z"
    },
    "id": "Qk38Sw4MO4eh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 5.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pN3HtDONh5TX"
   },
   "source": [
    "Note: `Dataset.cache`  stores the data form the first epoch and replays it in order. So using `.cache` disables any shuffles earlier in the pipeline. Below the `.shuffle` is added back in after `.cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:26.683257Z",
     "iopub.status.busy": "2021-06-16T15:06:26.682703Z",
     "iopub.status.idle": "2021-06-16T15:06:27.908914Z",
     "shell.execute_reply": "2021-06-16T15:06:27.909258Z"
    },
    "id": "r5Jj72MrPbnh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 813 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN7uUBjmgNZ9"
   },
   "source": [
    "Note: `snapshot` files are meant for *temporary* storage of a dataset while in use. This is *not* a format for long term storage. The file format is considered an internal detail, and not guaranteed between TensorFlow versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:27.914745Z",
     "iopub.status.busy": "2021-06-16T15:06:27.914101Z",
     "iopub.status.idle": "2021-06-16T15:06:29.535076Z",
     "shell.execute_reply": "2021-06-16T15:06:29.534477Z"
    },
    "id": "PHGD1E8ktUvW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "snapshot = tf.data.experimental.snapshot('titanic.tfsnap')\n",
    "snapshotting = traffic_volume_csv_gz_ds.apply(snapshot).shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUSSegnMCGRz"
   },
   "source": [
    "If data loading is slowed by loading csv files, and `cache` and `snapshot` are insufficient for use case, consider re-encoding the data into a more streamlined format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0iGXv9pC5kr"
   },
   "source": [
    "### Multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FFzHQrCDH4w"
   },
   "source": [
    "All the examples so far in this section could easily be done without `tf.data`. One place where `tf.data` can really simplify things is when dealing with collections of files.\n",
    "\n",
    "For example, the [character font images](https://archive.ics.uci.edu/ml/datasets/Character+Font+Images) dataset is distributed as a collection of csv files, one per font.\n",
    "\n",
    "Download the dataset, and have a look at the files inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:29.539188Z",
     "iopub.status.busy": "2021-06-16T15:06:29.538598Z",
     "iopub.status.idle": "2021-06-16T15:06:43.268560Z",
     "shell.execute_reply": "2021-06-16T15:06:43.267974Z"
    },
    "id": "RmVknMdJh5ks"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\n",
      "160317440/160313983 [==============================] - 106s 1us/step\n"
     ]
    }
   ],
   "source": [
    "fonts_zip = tf.keras.utils.get_file(\n",
    "    'fonts.zip',  \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n",
    "    cache_dir='.', cache_subdir='fonts',\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:43.274225Z",
     "iopub.status.busy": "2021-06-16T15:06:43.272843Z",
     "iopub.status.idle": "2021-06-16T15:06:43.276901Z",
     "shell.execute_reply": "2021-06-16T15:06:43.277287Z"
    },
    "id": "xsDlMCnyi55e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fonts\\\\AGENCY.csv',\n",
       " 'fonts\\\\ARIAL.csv',\n",
       " 'fonts\\\\BAITI.csv',\n",
       " 'fonts\\\\BANKGOTHIC.csv',\n",
       " 'fonts\\\\BASKERVILLE.csv',\n",
       " 'fonts\\\\BAUHAUS.csv',\n",
       " 'fonts\\\\BELL.csv',\n",
       " 'fonts\\\\BERLIN.csv',\n",
       " 'fonts\\\\BERNARD.csv',\n",
       " 'fonts\\\\BITSTREAMVERA.csv']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs =  sorted(str(p) for p in pathlib.Path('fonts').glob(\"*.csv\"))\n",
    "\n",
    "font_csvs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:43.281018Z",
     "iopub.status.busy": "2021-06-16T15:06:43.280361Z",
     "iopub.status.idle": "2021-06-16T15:06:43.283438Z",
     "shell.execute_reply": "2021-06-16T15:06:43.282972Z"
    },
    "id": "lRAEJx9ROAGl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(font_csvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19Udrw9iG-FS"
   },
   "source": [
    "When dealing with a bunch of files, pass a glob-style `file_pattern` to the `experimental.make_csv_dataset` function. The order of the files is shuffled each iteration.\n",
    "\n",
    "Use the `num_parallel_reads` argument to set how many files are read in parallel and interleaved together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:43.287541Z",
     "iopub.status.busy": "2021-06-16T15:06:43.286765Z",
     "iopub.status.idle": "2021-06-16T15:06:44.099899Z",
     "shell.execute_reply": "2021-06-16T15:06:44.100394Z"
    },
    "id": "6TSUNdT6iG58"
   },
   "outputs": [],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=10, num_epochs=1,\n",
    "    num_parallel_reads=20,\n",
    "    shuffle_buffer_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMoexinLHYFa"
   },
   "source": [
    "These csv files have the images flattened out into a single row. The column names are formatted `r{row}c{column}`. Here's the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:44.107542Z",
     "iopub.status.busy": "2021-06-16T15:06:44.106917Z",
     "iopub.status.idle": "2021-06-16T15:06:45.396587Z",
     "shell.execute_reply": "2021-06-16T15:06:45.396964Z"
    },
    "id": "RmFvBWxxi3pq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "font                : [b'JUICE' b'CALIBRI' b'CONSOLAS' b'YI BAITI' b'MV_BOLI' b'BODONI' b'GILL'\n",
      " b'GOTHICE' b'LEELAWADEE' b'YI BAITI']\n",
      "fontVariant         : [b'JUICE ITC' b'CALIBRI LIGHT' b'CONSOLAS' b'MICROSOFT YI BAITI'\n",
      " b'MV BOLI' b'BODONI MT POSTER COMPRESSED'\n",
      " b'GILL SANS ULTRA BOLD CONDENSED' b'GOTHICE' b'LEELAWADEE UI SEMILIGHT'\n",
      " b'MICROSOFT YI BAITI']\n",
      "m_label             : [ 8724  8976  9548 42075    40  8217   216  1097  9674 41811]\n",
      "strength            : [0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n",
      "italic              : [0 0 0 0 0 0 1 1 0 0]\n",
      "orientation         : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "m_top               : [34 64 57 30 40 33 35 56 45 30]\n",
      "m_left              : [23 23 20 27 26 21 21 29 23 26]\n",
      "originalH           : [59 10  5 48 63 17 53 41 47 50]\n",
      "originalW           : [34 28 37 32 34  6 53 64 32 35]\n",
      "h                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "w                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "r0c0                : [255 255 255 255   1   1   1   1   1   1]\n",
      "r0c1                : [255 255 255 224   1   1   1   1   1   1]\n",
      "r0c2                : [255 255 255   1   1   1   1   1   1   1]\n",
      "r0c3                : [255 255 255   1   1   1   1   1   1   1]\n",
      "...\n",
      "[total: 412 features]\n"
     ]
    }
   ],
   "source": [
    "for features in fonts_ds.take(1):\n",
    "  for i, (name, value) in enumerate(features.items()):\n",
    "    if i>15:\n",
    "      break\n",
    "    print(f\"{name:20s}: {value}\")\n",
    "print('...')\n",
    "print(f\"[total: {len(features)} features]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrC3sKdeOhb5"
   },
   "source": [
    "#### Optional: Packing fields\n",
    "\n",
    "Before trying to use this dataset be sure to pack the pixels into an image-tensor. Here is code that parses the column names to build images for each example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:45.402839Z",
     "iopub.status.busy": "2021-06-16T15:06:45.402203Z",
     "iopub.status.idle": "2021-06-16T15:06:45.404275Z",
     "shell.execute_reply": "2021-06-16T15:06:45.403845Z"
    },
    "id": "hct5EMEWNyfH"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def make_images(features):\n",
    "  image = [None]*400\n",
    "  new_feats = {}\n",
    "\n",
    "  for name, value in features.items():\n",
    "    match = re.match('r(\\d+)c(\\d+)', name)\n",
    "    if match:\n",
    "      image[int(match.group(1))*20+int(match.group(2))] = value\n",
    "    else:\n",
    "      new_feats[name] = value\n",
    "\n",
    "  image = tf.stack(image, axis=0)\n",
    "  image = tf.reshape(image, [20, 20, -1])\n",
    "  new_feats['image'] = image\n",
    "\n",
    "  return new_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61qy8utAwARP"
   },
   "source": [
    "Apply that function to each batch in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:45.411040Z",
     "iopub.status.busy": "2021-06-16T15:06:45.410427Z",
     "iopub.status.idle": "2021-06-16T15:06:47.191955Z",
     "shell.execute_reply": "2021-06-16T15:06:47.191213Z"
    },
    "id": "DJnnfIW9baE4"
   },
   "outputs": [],
   "source": [
    "fonts_image_ds = fonts_ds.map(make_images)\n",
    "\n",
    "for features in fonts_image_ds.take(1):\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ThqrthGwHSm"
   },
   "source": [
    "Plot the resulting images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:06:47.211039Z",
     "iopub.status.busy": "2021-06-16T15:06:47.210411Z",
     "iopub.status.idle": "2021-06-16T15:06:47.673763Z",
     "shell.execute_reply": "2021-06-16T15:06:47.674155Z"
    },
    "id": "I5dcey31T_tk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei\\.conda\\envs\\tf\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:240: RuntimeWarning: Glyph 41849 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Wei\\.conda\\envs\\tf\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:203: RuntimeWarning: Glyph 41849 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6), dpi=120)\n",
    "\n",
    "for n in range(9):\n",
    "  plt.subplot(3,3,n+1)\n",
    "  plt.imshow(features['image'][..., n])\n",
    "  plt.title(chr(features['m_label'][n]))\n",
    "  plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "csv.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
