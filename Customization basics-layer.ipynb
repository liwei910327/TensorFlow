{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60RdWsg1tETW"
   },
   "source": [
    "# Custom layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEu3q4jmpKVT"
   },
   "source": [
    "Using `tf.keras` as a high-level API for building neural networks. That said, most TensorFlow APIs are usable with eager execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:42.459537Z",
     "iopub.status.busy": "2021-06-16T15:02:42.458968Z",
     "iopub.status.idle": "2021-06-16T15:02:43.925747Z",
     "shell.execute_reply": "2021-06-16T15:02:43.925257Z"
    },
    "id": "Py0m-N6VgQFJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:43.929890Z",
     "iopub.status.busy": "2021-06-16T15:02:43.929125Z",
     "iopub.status.idle": "2021-06-16T15:02:45.292474Z",
     "shell.execute_reply": "2021-06-16T15:02:45.292821Z"
    },
    "id": "TluWFcB_2nP5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ae932be897c3>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSFfVVjkrrsI"
   },
   "source": [
    "## Layers: common sets of useful operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:45.297345Z",
     "iopub.status.busy": "2021-06-16T15:02:45.296790Z",
     "iopub.status.idle": "2021-06-16T15:02:45.304188Z",
     "shell.execute_reply": "2021-06-16T15:02:45.304542Z"
    },
    "id": "8PyXlPl-4TzQ"
   },
   "outputs": [],
   "source": [
    "# In the tf.keras.layers package, layers are objects. To construct a layer,\n",
    "# simply construct the object. Most layers take as a first argument the number\n",
    "# of output dimensions / channels.\n",
    "layer = tf.keras.layers.Dense(100)\n",
    "# The number of input dimensions is often unnecessary, as it can be inferred\n",
    "# the first time the layer is used, but it can be provided if you want to\n",
    "# specify it manually, which is useful in some complex models.\n",
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fn69xxPO5Psr"
   },
   "source": [
    "The full list of pre-existing layers can be seen in [the documentation]. It includes Dense (a fully-connected layer),\n",
    "Conv2D, LSTM, BatchNormalization, Dropout, and many others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:45.316667Z",
     "iopub.status.busy": "2021-06-16T15:02:45.316066Z",
     "iopub.status.idle": "2021-06-16T15:02:45.987653Z",
     "shell.execute_reply": "2021-06-16T15:02:45.988073Z"
    },
    "id": "E3XKNknP5Mhb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use a layer, simply call it.\n",
    "layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:45.992129Z",
     "iopub.status.busy": "2021-06-16T15:02:45.991565Z",
     "iopub.status.idle": "2021-06-16T15:02:45.996940Z",
     "shell.execute_reply": "2021-06-16T15:02:45.996533Z"
    },
    "id": "Wt_Nsv-L5t2s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[-0.21981409, -0.556763  , -0.00722533, -0.6025204 ,  0.11806881,\n",
       "          0.49927992,  0.5916706 ,  0.10783505,  0.52594155,  0.01104635],\n",
       "        [ 0.39414054,  0.34683132,  0.46735483, -0.05229956,  0.23294812,\n",
       "          0.12009841, -0.48703358,  0.6022077 , -0.32566792,  0.07034373],\n",
       "        [-0.40987128, -0.59633034, -0.2497774 ,  0.5014308 ,  0.31765997,\n",
       "         -0.37472853, -0.03741425, -0.31100833,  0.47611362, -0.38121036],\n",
       "        [ 0.39433593, -0.45738918, -0.17615733, -0.57191867,  0.24638736,\n",
       "         -0.4380179 , -0.20712337,  0.16085309, -0.41435593, -0.46428642],\n",
       "        [ 0.3286665 ,  0.09785253, -0.4027183 ,  0.17111355, -0.14382827,\n",
       "          0.34538722, -0.5022633 ,  0.31599796,  0.06772214, -0.20462254]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layers have many useful methods. For example, you can inspect all variables\n",
    "# in a layer using `layer.variables` and trainable variables using\n",
    "# `layer.trainable_variables`. In this case a fully-connected layer\n",
    "# will have variables for weights and biases.\n",
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:46.000550Z",
     "iopub.status.busy": "2021-06-16T15:02:46.000021Z",
     "iopub.status.idle": "2021-06-16T15:02:46.004824Z",
     "shell.execute_reply": "2021-06-16T15:02:46.004408Z"
    },
    "id": "6ilvKjz8_4MQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[-0.21981409, -0.556763  , -0.00722533, -0.6025204 ,  0.11806881,\n",
       "          0.49927992,  0.5916706 ,  0.10783505,  0.52594155,  0.01104635],\n",
       "        [ 0.39414054,  0.34683132,  0.46735483, -0.05229956,  0.23294812,\n",
       "          0.12009841, -0.48703358,  0.6022077 , -0.32566792,  0.07034373],\n",
       "        [-0.40987128, -0.59633034, -0.2497774 ,  0.5014308 ,  0.31765997,\n",
       "         -0.37472853, -0.03741425, -0.31100833,  0.47611362, -0.38121036],\n",
       "        [ 0.39433593, -0.45738918, -0.17615733, -0.57191867,  0.24638736,\n",
       "         -0.4380179 , -0.20712337,  0.16085309, -0.41435593, -0.46428642],\n",
       "        [ 0.3286665 ,  0.09785253, -0.4027183 ,  0.17111355, -0.14382827,\n",
       "          0.34538722, -0.5022633 ,  0.31599796,  0.06772214, -0.20462254]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The variables are also accessible through nice accessors\n",
    "layer.kernel, layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0kDbE54-5VS"
   },
   "source": [
    "## Implementing custom layers\n",
    "\n",
    "The best way to implement own layer is extending the tf.keras.Layer class and implementing:\n",
    "\n",
    "1. `__init__` , where users can do all input-independent initialization\n",
    "2. `build`, where users know the shapes of the input tensors and can do the rest of the initialization\n",
    "3. `call`, where users do the forward computation\n",
    "\n",
    "Note that users don't have to wait until `build` is called to create variables, users can also create them in `__init__`. However, the advantage of creating them in `build` is that it enables late variable creation based on the shape of the inputs the layer will operate on. On the other hand, creating variables in `__init__` would mean that shapes required to create the variables will need to be explicitly specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:46.010031Z",
     "iopub.status.busy": "2021-06-16T15:02:46.009483Z",
     "iopub.status.idle": "2021-06-16T15:02:46.011722Z",
     "shell.execute_reply": "2021-06-16T15:02:46.011262Z"
    },
    "id": "5Byl3n1k5kIy"
   },
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_outputs):\n",
    "    super(MyDenseLayer, self).__init__()\n",
    "    self.num_outputs = num_outputs\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.kernel = self.add_weight(\"kernel\",\n",
    "                                  shape=[int(input_shape[-1]),\n",
    "                                         self.num_outputs])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "layer = MyDenseLayer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:46.015823Z",
     "iopub.status.busy": "2021-06-16T15:02:46.015164Z",
     "iopub.status.idle": "2021-06-16T15:02:46.018208Z",
     "shell.execute_reply": "2021-06-16T15:02:46.018529Z"
    },
    "id": "vrmBsYGOnuGO"
   },
   "outputs": [],
   "source": [
    "_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:46.021961Z",
     "iopub.status.busy": "2021-06-16T15:02:46.021393Z",
     "iopub.status.idle": "2021-06-16T15:02:46.023590Z",
     "shell.execute_reply": "2021-06-16T15:02:46.023928Z"
    },
    "id": "1bsLjiPfnvat"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_dense_layer/kernel:0']\n"
     ]
    }
   ],
   "source": [
    "print([var.name for var in layer.trainable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tk8E2vY0-z4Z"
   },
   "source": [
    "Overall code is easier to read and maintain if it uses standard layers whenever possible, as other readers will be familiar with the behavior of standard layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qhg4KlbKrs3G"
   },
   "source": [
    "## Models: Composing layers\n",
    "\n",
    "Many interesting layer-like things in machine learning models are implemented by composing existing layers. For example, each residual block in a resnet is a composition of convolutions, batch normalizations, and a shortcut. Layers can be nested inside other layers.\n",
    "\n",
    "Typically users inherit from `keras.Model` when need the model methods like: `Model.fit`,`Model.evaluate`, and `Model.save` (see [Custom Keras layers and models](../../guide/keras/custom_layers_and_models.ipynb) for details).\n",
    "\n",
    "One other feature provided by `keras.Model` (instead of `keras.layers.Layer`) is that in addition to tracking variables, a `keras.Model` also tracks its internal layers, making them easier to inspect.\n",
    "\n",
    "Here is a ResNet block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:46.031862Z",
     "iopub.status.busy": "2021-06-16T15:02:46.031243Z",
     "iopub.status.idle": "2021-06-16T15:02:46.042016Z",
     "shell.execute_reply": "2021-06-16T15:02:46.041461Z"
    },
    "id": "N30DTXiRASlb"
   },
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters):\n",
    "    super(ResnetIdentityBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:46.046443Z",
     "iopub.status.busy": "2021-06-16T15:02:46.045838Z",
     "iopub.status.idle": "2021-06-16T15:02:48.167055Z",
     "shell.execute_reply": "2021-06-16T15:02:48.166512Z"
    },
    "id": "7D8ZR5mqtokj"
   },
   "outputs": [],
   "source": [
    "_ = block(tf.zeros([1, 2, 3, 3])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:48.170952Z",
     "iopub.status.busy": "2021-06-16T15:02:48.170399Z",
     "iopub.status.idle": "2021-06-16T15:02:48.173463Z",
     "shell.execute_reply": "2021-06-16T15:02:48.173847Z"
    },
    "id": "MJ8rzFpdoE_m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x2c194150d30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2c194401a00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2c19419ad30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2c19419a190>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2c1fc3af250>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2c1fc3af700>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:48.177833Z",
     "iopub.status.busy": "2021-06-16T15:02:48.177277Z",
     "iopub.status.idle": "2021-06-16T15:02:48.180477Z",
     "shell.execute_reply": "2021-06-16T15:02:48.180039Z"
    },
    "id": "dewldLuDvQRM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:48.184488Z",
     "iopub.status.busy": "2021-06-16T15:02:48.183243Z",
     "iopub.status.idle": "2021-06-16T15:02:48.188762Z",
     "shell.execute_reply": "2021-06-16T15:02:48.188336Z"
    },
    "id": "FrqIXeSetaYi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_identity_block\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchN  multiple                  4         \n",
      "ormalization)                                                    \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batc  multiple                  8         \n",
      "hNormalization)                                                  \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batc  multiple                  12        \n",
      "hNormalization)                                                  \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYfucVw65PMj"
   },
   "source": [
    "Much of the time, however, models which compose many layers simply call one layer after the other. This can be done in very little code using `tf.keras.Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:48.198056Z",
     "iopub.status.busy": "2021-06-16T15:02:48.197496Z",
     "iopub.status.idle": "2021-06-16T15:02:48.245511Z",
     "shell.execute_reply": "2021-06-16T15:02:48.245091Z"
    },
    "id": "L9frk7Ur4uvJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
    "                                                    input_shape=(\n",
    "                                                        None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:02:48.250118Z",
     "iopub.status.busy": "2021-06-16T15:02:48.249131Z",
     "iopub.status.idle": "2021-06-16T15:02:48.254968Z",
     "shell.execute_reply": "2021-06-16T15:02:48.255430Z"
    },
    "id": "tVAsbFITuScB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, None, None, 1)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batc  (None, None, None, 1)     4         \n",
      "hNormalization)                                                  \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 2)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batc  (None, None, None, 2)     8         \n",
      "hNormalization)                                                  \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 3)     9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batc  (None, None, None, 3)     12        \n",
      "hNormalization)                                                  \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_seq.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "custom_layers.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
